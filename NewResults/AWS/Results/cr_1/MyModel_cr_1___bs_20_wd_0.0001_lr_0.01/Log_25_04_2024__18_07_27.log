2024-04-25 18:07:27,315 This is a summery of the run:
2024-04-25 18:07:27,315 Batch size for this run: 20
2024-04-25 18:07:27,315 Size of original image: 32 X 32
2024-04-25 18:07:27,315 number of masks: 1024
2024-04-25 18:07:27,315 Compression ratio: 1
2024-04-25 18:07:27,315 epochs : 40
2024-04-25 18:07:27,315 one learning rate: 0.01
2024-04-25 18:07:27,315 optimizer: adam
2024-04-25 18:07:27,315 weight_decay: 0.0001
2024-04-25 18:07:27,315 ***************************************************************************


2024-04-25 18:07:27,315 learning rate: 0.01
2024-04-25 18:07:35,372 Epoch number 0, batch number 0/4:       batch loss 0.4642946124076843
2024-04-25 18:07:39,450 Epoch number 0, batch number 1/4:       batch loss 0.08160066604614258
2024-04-25 18:07:43,286 Epoch number 0, batch number 2/4:       batch loss 0.09228421747684479
2024-04-25 18:07:45,235 Epoch number 0, batch number 3/4:       batch loss 0.07007337361574173
2024-04-25 18:07:47,864 Epoch number 0, batch number 0/1:       batch loss 0.05945573002099991
2024-04-25 18:07:48,097 Epoch: 1 	Training Loss: 0.008853
2024-04-25 18:07:48,097 Time for epoch 1 : 20 sec
2024-04-25 18:07:48,097 lr for epoch 1 is 0.01000
2024-04-25 18:07:52,070 Epoch number 1, batch number 0/4:       batch loss 0.048346005380153656
2024-04-25 18:07:54,494 Epoch number 1, batch number 1/4:       batch loss 0.03830043226480484
2024-04-25 18:07:56,533 Epoch number 1, batch number 2/4:       batch loss 0.053013116121292114
2024-04-25 18:07:58,466 Epoch number 1, batch number 3/4:       batch loss 0.06319373846054077
2024-04-25 18:08:01,163 Epoch number 1, batch number 0/1:       batch loss 0.04502076655626297
2024-04-25 18:08:01,371 Epoch: 2 	Training Loss: 0.002536
2024-04-25 18:08:01,371 Time for epoch 2 : 13 sec
2024-04-25 18:08:01,371 lr for epoch 2 is 0.01000
2024-04-25 18:08:05,427 Epoch number 2, batch number 0/4:       batch loss 0.05295505374670029
2024-04-25 18:08:07,851 Epoch number 2, batch number 1/4:       batch loss 0.04158536344766617
2024-04-25 18:08:09,798 Epoch number 2, batch number 2/4:       batch loss 0.04283510893583298
2024-04-25 18:08:11,729 Epoch number 2, batch number 3/4:       batch loss 0.033485449850559235
2024-04-25 18:08:14,460 Epoch number 2, batch number 0/1:       batch loss 0.04155820608139038
2024-04-25 18:08:14,686 Epoch: 3 	Training Loss: 0.002136
2024-04-25 18:08:14,686 Time for epoch 3 : 13 sec
2024-04-25 18:08:14,686 lr for epoch 3 is 0.01000
2024-04-25 18:08:18,671 Epoch number 3, batch number 0/4:       batch loss 0.043050676584243774
2024-04-25 18:08:21,102 Epoch number 3, batch number 1/4:       batch loss 0.04405606538057327
2024-04-25 18:08:23,077 Epoch number 3, batch number 2/4:       batch loss 0.06068526580929756
2024-04-25 18:08:25,021 Epoch number 3, batch number 3/4:       batch loss 0.031161382794380188
2024-04-25 18:08:27,695 Epoch number 3, batch number 0/1:       batch loss 0.038204193115234375
2024-04-25 18:08:27,933 Epoch: 4 	Training Loss: 0.002237
2024-04-25 18:08:27,933 Time for epoch 4 : 13 sec
2024-04-25 18:08:27,934 lr for epoch 4 is 0.01000
2024-04-25 18:08:31,887 Epoch number 4, batch number 0/4:       batch loss 0.03890740126371384
2024-04-25 18:08:34,316 Epoch number 4, batch number 1/4:       batch loss 0.03554431349039078
2024-04-25 18:08:36,276 Epoch number 4, batch number 2/4:       batch loss 0.04268224164843559
2024-04-25 18:08:38,203 Epoch number 4, batch number 3/4:       batch loss 0.036868609488010406
2024-04-25 18:08:40,999 Epoch number 4, batch number 0/1:       batch loss 0.04524533823132515
2024-04-25 18:08:41,180 Epoch: 5 	Training Loss: 0.001925
2024-04-25 18:08:41,181 Time for epoch 5 : 13 sec
2024-04-25 18:08:41,181 lr for epoch 5 is 0.01000
2024-04-25 18:08:45,126 Epoch number 5, batch number 0/4:       batch loss 0.037300609052181244
2024-04-25 18:08:47,524 Epoch number 5, batch number 1/4:       batch loss 0.03840584680438042
2024-04-25 18:08:49,550 Epoch number 5, batch number 2/4:       batch loss 0.039096273481845856
2024-04-25 18:08:51,480 Epoch number 5, batch number 3/4:       batch loss 0.028969600796699524
2024-04-25 18:08:54,366 Epoch number 5, batch number 0/1:       batch loss 0.030520185828208923
2024-04-25 18:08:54,554 Epoch: 6 	Training Loss: 0.001797
2024-04-25 18:08:54,554 Time for epoch 6 : 13 sec
2024-04-25 18:08:54,554 lr for epoch 6 is 0.01000
2024-04-25 18:08:58,502 Epoch number 6, batch number 0/4:       batch loss 0.03064918890595436
2024-04-25 18:09:00,858 Epoch number 6, batch number 1/4:       batch loss 0.033040184527635574
2024-04-25 18:09:02,837 Epoch number 6, batch number 2/4:       batch loss 0.029036277905106544
2024-04-25 18:09:04,809 Epoch number 6, batch number 3/4:       batch loss 0.035035960376262665
2024-04-25 18:09:07,552 Epoch number 6, batch number 0/1:       batch loss 0.03295785188674927
2024-04-25 18:09:07,764 Epoch: 7 	Training Loss: 0.001597
2024-04-25 18:09:07,764 Time for epoch 7 : 13 sec
2024-04-25 18:09:07,764 lr for epoch 7 is 0.01000
2024-04-25 18:09:11,751 Epoch number 7, batch number 0/4:       batch loss 0.03674399480223656
2024-04-25 18:09:14,159 Epoch number 7, batch number 1/4:       batch loss 0.027089932933449745
2024-04-25 18:09:16,170 Epoch number 7, batch number 2/4:       batch loss 0.020123576745390892
2024-04-25 18:09:18,096 Epoch number 7, batch number 3/4:       batch loss 0.02506265975534916
2024-04-25 18:09:20,935 Epoch number 7, batch number 0/1:       batch loss 0.028011584654450417
2024-04-25 18:09:21,168 Epoch: 8 	Training Loss: 0.001363
2024-04-25 18:09:21,168 Time for epoch 8 : 13 sec
2024-04-25 18:09:21,168 lr for epoch 8 is 0.01000
2024-04-25 18:09:25,156 Epoch number 8, batch number 0/4:       batch loss 0.025002311915159225
2024-04-25 18:09:27,515 Epoch number 8, batch number 1/4:       batch loss 0.03325561061501503
2024-04-25 18:09:29,482 Epoch number 8, batch number 2/4:       batch loss 0.021901924163103104
2024-04-25 18:09:31,489 Epoch number 8, batch number 3/4:       batch loss 0.028771575540304184
2024-04-25 18:09:34,376 Epoch number 8, batch number 0/1:       batch loss 0.022625787183642387
2024-04-25 18:09:34,560 Epoch: 9 	Training Loss: 0.001362
2024-04-25 18:09:34,560 Time for epoch 9 : 13 sec
2024-04-25 18:09:34,560 lr for epoch 9 is 0.01000
2024-04-25 18:09:38,527 Epoch number 9, batch number 0/4:       batch loss 0.02951001189649105
2024-04-25 18:09:40,898 Epoch number 9, batch number 1/4:       batch loss 0.01812395080924034
2024-04-25 18:09:42,897 Epoch number 9, batch number 2/4:       batch loss 0.02318180724978447
2024-04-25 18:09:44,840 Epoch number 9, batch number 3/4:       batch loss 0.012698015198111534
2024-04-25 18:09:47,648 Epoch number 9, batch number 0/1:       batch loss 0.01389290951192379
2024-04-25 18:09:47,845 Epoch: 10 	Training Loss: 0.001044
2024-04-25 18:09:47,845 Time for epoch 10 : 13 sec
2024-04-25 18:09:47,845 lr for epoch 10 is 0.01000
2024-04-25 18:09:51,811 Epoch number 10, batch number 0/4:       batch loss 0.016479525715112686
2024-04-25 18:09:54,285 Epoch number 10, batch number 1/4:       batch loss 0.011481205932796001
2024-04-25 18:09:56,294 Epoch number 10, batch number 2/4:       batch loss 0.019214952364563942
2024-04-25 18:09:58,238 Epoch number 10, batch number 3/4:       batch loss 0.01238742284476757
2024-04-25 18:10:00,963 Epoch number 10, batch number 0/1:       batch loss 0.015080447308719158
2024-04-25 18:10:01,158 Epoch: 11 	Training Loss: 0.000745
2024-04-25 18:10:01,159 Time for epoch 11 : 13 sec
2024-04-25 18:10:01,159 lr for epoch 11 is 0.01000
2024-04-25 18:10:05,077 Epoch number 11, batch number 0/4:       batch loss 0.019281726330518723
2024-04-25 18:10:07,539 Epoch number 11, batch number 1/4:       batch loss 0.008344667963683605
2024-04-25 18:10:09,479 Epoch number 11, batch number 2/4:       batch loss 0.008533088490366936
2024-04-25 18:10:11,420 Epoch number 11, batch number 3/4:       batch loss 0.014078430831432343
2024-04-25 18:10:14,190 Epoch number 11, batch number 0/1:       batch loss 0.013669152744114399
2024-04-25 18:10:14,394 Epoch: 12 	Training Loss: 0.000628
2024-04-25 18:10:14,395 Time for epoch 12 : 13 sec
2024-04-25 18:10:14,395 lr for epoch 12 is 0.01000
2024-04-25 18:10:18,319 Epoch number 12, batch number 0/4:       batch loss 0.013538369908928871
2024-04-25 18:10:20,738 Epoch number 12, batch number 1/4:       batch loss 0.008155792951583862
2024-04-25 18:10:22,746 Epoch number 12, batch number 2/4:       batch loss 0.01060777809470892
2024-04-25 18:10:24,683 Epoch number 12, batch number 3/4:       batch loss 0.005634142551571131
2024-04-25 18:10:27,393 Epoch number 12, batch number 0/1:       batch loss 0.010938528925180435
2024-04-25 18:10:27,606 Epoch: 13 	Training Loss: 0.000474
2024-04-25 18:10:27,607 Time for epoch 13 : 13 sec
2024-04-25 18:10:27,607 lr for epoch 13 is 0.01000
2024-04-25 18:10:31,550 Epoch number 13, batch number 0/4:       batch loss 0.01320126187056303
2024-04-25 18:10:34,041 Epoch number 13, batch number 1/4:       batch loss 0.006521139293909073
2024-04-25 18:10:36,014 Epoch number 13, batch number 2/4:       batch loss 0.007462198846042156
2024-04-25 18:10:37,959 Epoch number 13, batch number 3/4:       batch loss 0.0046363696455955505
2024-04-25 18:10:40,766 Epoch number 13, batch number 0/1:       batch loss 0.007053793873637915
2024-04-25 18:10:40,977 Epoch: 14 	Training Loss: 0.000398
2024-04-25 18:10:40,977 Time for epoch 14 : 13 sec
2024-04-25 18:10:40,977 lr for epoch 14 is 0.01000
2024-04-25 18:10:44,885 Epoch number 14, batch number 0/4:       batch loss 0.0060431272722780704
2024-04-25 18:10:47,309 Epoch number 14, batch number 1/4:       batch loss 0.006054820958524942
2024-04-25 18:10:49,377 Epoch number 14, batch number 2/4:       batch loss 0.005787902511656284
2024-04-25 18:10:51,310 Epoch number 14, batch number 3/4:       batch loss 0.005639974493533373
2024-04-25 18:10:54,192 Epoch number 14, batch number 0/1:       batch loss 0.004711328539997339
2024-04-25 18:10:54,366 Epoch: 15 	Training Loss: 0.000294
2024-04-25 18:10:54,367 Time for epoch 15 : 13 sec
2024-04-25 18:10:54,367 lr for epoch 15 is 0.01000
2024-04-25 18:10:58,390 Epoch number 15, batch number 0/4:       batch loss 0.005376073066145182
2024-04-25 18:11:00,841 Epoch number 15, batch number 1/4:       batch loss 0.004509835038334131
2024-04-25 18:11:02,861 Epoch number 15, batch number 2/4:       batch loss 0.005443914327770472
2024-04-25 18:11:04,828 Epoch number 15, batch number 3/4:       batch loss 0.004387478344142437
2024-04-25 18:11:07,553 Epoch number 15, batch number 0/1:       batch loss 0.004126175306737423
2024-04-25 18:11:07,748 Epoch: 16 	Training Loss: 0.000246
2024-04-25 18:11:07,748 Time for epoch 16 : 13 sec
2024-04-25 18:11:07,748 lr for epoch 16 is 0.01000
2024-04-25 18:11:11,710 Epoch number 16, batch number 0/4:       batch loss 0.002976403571665287
2024-04-25 18:11:14,114 Epoch number 16, batch number 1/4:       batch loss 0.0037247217260301113
2024-04-25 18:11:16,125 Epoch number 16, batch number 2/4:       batch loss 0.004346592351794243
2024-04-25 18:11:18,103 Epoch number 16, batch number 3/4:       batch loss 0.004741068929433823
2024-04-25 18:11:20,848 Epoch number 16, batch number 0/1:       batch loss 0.005102175287902355
2024-04-25 18:11:21,063 Epoch: 17 	Training Loss: 0.000197
2024-04-25 18:11:21,063 Time for epoch 17 : 13 sec
2024-04-25 18:11:21,063 lr for epoch 17 is 0.01000
2024-04-25 18:11:24,984 Epoch number 17, batch number 0/4:       batch loss 0.00381133402697742
2024-04-25 18:11:27,345 Epoch number 17, batch number 1/4:       batch loss 0.004225308541208506
2024-04-25 18:11:29,401 Epoch number 17, batch number 2/4:       batch loss 0.0035443739034235477
2024-04-25 18:11:31,345 Epoch number 17, batch number 3/4:       batch loss 0.004626837559044361
2024-04-25 18:11:34,088 Epoch number 17, batch number 0/1:       batch loss 0.0037514548748731613
2024-04-25 18:11:34,312 Epoch: 18 	Training Loss: 0.000203
2024-04-25 18:11:34,312 Time for epoch 18 : 13 sec
2024-04-25 18:11:34,312 lr for epoch 18 is 0.01000
2024-04-25 18:11:38,336 Epoch number 18, batch number 0/4:       batch loss 0.0038295541889965534
2024-04-25 18:11:40,797 Epoch number 18, batch number 1/4:       batch loss 0.0029863498639315367
2024-04-25 18:11:42,764 Epoch number 18, batch number 2/4:       batch loss 0.0038340180180966854
2024-04-25 18:11:44,706 Epoch number 18, batch number 3/4:       batch loss 0.004542771261185408
2024-04-25 18:11:47,337 Epoch number 18, batch number 0/1:       batch loss 0.0033125276677310467
2024-04-25 18:11:47,547 Epoch: 19 	Training Loss: 0.000190
2024-04-25 18:11:47,548 Time for epoch 19 : 13 sec
2024-04-25 18:11:47,548 lr for epoch 19 is 0.01000
2024-04-25 18:11:51,470 Epoch number 19, batch number 0/4:       batch loss 0.0033713201992213726
2024-04-25 18:11:53,894 Epoch number 19, batch number 1/4:       batch loss 0.004988017491996288
2024-04-25 18:11:55,897 Epoch number 19, batch number 2/4:       batch loss 0.005480573512613773
2024-04-25 18:11:57,860 Epoch number 19, batch number 3/4:       batch loss 0.00344291259534657
2024-04-25 18:12:00,629 Epoch number 19, batch number 0/1:       batch loss 0.004514784552156925
2024-04-25 18:12:00,833 Epoch: 20 	Training Loss: 0.000216
2024-04-25 18:12:00,833 Time for epoch 20 : 13 sec
2024-04-25 18:12:00,833 lr for epoch 20 is 0.01000
2024-04-25 18:12:04,813 Epoch number 20, batch number 0/4:       batch loss 0.0037967204116284847
2024-04-25 18:12:07,164 Epoch number 20, batch number 1/4:       batch loss 0.004299936816096306
2024-04-25 18:12:09,166 Epoch number 20, batch number 2/4:       batch loss 0.004520823247730732
2024-04-25 18:12:11,152 Epoch number 20, batch number 3/4:       batch loss 0.004799524322152138
2024-04-25 18:12:13,822 Epoch number 20, batch number 0/1:       batch loss 0.003489666385576129
2024-04-25 18:12:14,025 Epoch: 21 	Training Loss: 0.000218
2024-04-25 18:12:14,025 Time for epoch 21 : 13 sec
2024-04-25 18:12:14,025 lr for epoch 21 is 0.01000
2024-04-25 18:12:18,029 Epoch number 21, batch number 0/4:       batch loss 0.004178442992269993
2024-04-25 18:12:20,428 Epoch number 21, batch number 1/4:       batch loss 0.003410767065361142
2024-04-25 18:12:22,419 Epoch number 21, batch number 2/4:       batch loss 0.003997169900685549
2024-04-25 18:12:24,390 Epoch number 21, batch number 3/4:       batch loss 0.003948690369725227
2024-04-25 18:12:27,133 Epoch number 21, batch number 0/1:       batch loss 0.003998574800789356
2024-04-25 18:12:27,338 Epoch: 22 	Training Loss: 0.000194
2024-04-25 18:12:27,339 Time for epoch 22 : 13 sec
2024-04-25 18:12:27,339 lr for epoch 22 is 0.01000
2024-04-25 18:12:31,336 Epoch number 22, batch number 0/4:       batch loss 0.0033604870550334454
2024-04-25 18:12:33,690 Epoch number 22, batch number 1/4:       batch loss 0.004529510624706745
2024-04-25 18:12:35,661 Epoch number 22, batch number 2/4:       batch loss 0.0033218027092516422
2024-04-25 18:12:37,594 Epoch number 22, batch number 3/4:       batch loss 0.0027529518119990826
2024-04-25 18:12:40,334 Epoch number 22, batch number 0/1:       batch loss 0.0032927063293755054
2024-04-25 18:12:40,508 Epoch: 23 	Training Loss: 0.000175
2024-04-25 18:12:40,509 Time for epoch 23 : 13 sec
2024-04-25 18:12:40,509 lr for epoch 23 is 0.01000
2024-04-25 18:12:44,539 Epoch number 23, batch number 0/4:       batch loss 0.0036336120683699846
2024-04-25 18:12:46,889 Epoch number 23, batch number 1/4:       batch loss 0.0030092771630734205
2024-04-25 18:12:48,878 Epoch number 23, batch number 2/4:       batch loss 0.004472249187529087
2024-04-25 18:12:50,889 Epoch number 23, batch number 3/4:       batch loss 0.003030550666153431
2024-04-25 18:12:53,538 Epoch number 23, batch number 0/1:       batch loss 0.00361056555993855
2024-04-25 18:12:53,746 Epoch: 24 	Training Loss: 0.000177
2024-04-25 18:12:53,747 Time for epoch 24 : 13 sec
2024-04-25 18:12:53,747 lr for epoch 24 is 0.01000
2024-04-25 18:12:57,749 Epoch number 24, batch number 0/4:       batch loss 0.003663610201328993
2024-04-25 18:13:00,157 Epoch number 24, batch number 1/4:       batch loss 0.003702787682414055
2024-04-25 18:13:02,182 Epoch number 24, batch number 2/4:       batch loss 0.00477172713726759
2024-04-25 18:13:04,127 Epoch number 24, batch number 3/4:       batch loss 0.003160127904266119
2024-04-25 18:13:06,848 Epoch number 24, batch number 0/1:       batch loss 0.004720635246485472
2024-04-25 18:13:07,051 Epoch: 25 	Training Loss: 0.000191
2024-04-25 18:13:07,052 Time for epoch 25 : 13 sec
2024-04-25 18:13:07,052 lr for epoch 25 is 0.01000
2024-04-25 18:13:11,027 Epoch number 25, batch number 0/4:       batch loss 0.004173089750111103
2024-04-25 18:13:13,738 Epoch number 25, batch number 1/4:       batch loss 0.004443158395588398
2024-04-25 18:13:15,696 Epoch number 25, batch number 2/4:       batch loss 0.0030653872527182102
2024-04-25 18:13:17,616 Epoch number 25, batch number 3/4:       batch loss 0.002980818971991539
2024-04-25 18:13:20,319 Epoch number 25, batch number 0/1:       batch loss 0.003611292690038681
2024-04-25 18:13:20,536 Epoch: 26 	Training Loss: 0.000183
2024-04-25 18:13:20,536 Time for epoch 26 : 13 sec
2024-04-25 18:13:20,536 lr for epoch 26 is 0.01000
2024-04-25 18:13:24,454 Epoch number 26, batch number 0/4:       batch loss 0.0034415300469845533
2024-04-25 18:13:26,820 Epoch number 26, batch number 1/4:       batch loss 0.0038816877640783787
2024-04-25 18:13:28,795 Epoch number 26, batch number 2/4:       batch loss 0.0022227722220122814
2024-04-25 18:13:30,778 Epoch number 26, batch number 3/4:       batch loss 0.005279236473143101
2024-04-25 18:13:33,531 Epoch number 26, batch number 0/1:       batch loss 0.0036608404479920864
2024-04-25 18:13:33,736 Epoch: 27 	Training Loss: 0.000185
2024-04-25 18:13:33,737 Time for epoch 27 : 13 sec
2024-04-25 18:13:33,737 lr for epoch 27 is 0.01000
2024-04-25 18:13:37,693 Epoch number 27, batch number 0/4:       batch loss 0.00371365319006145
2024-04-25 18:13:40,175 Epoch number 27, batch number 1/4:       batch loss 0.002630893373861909
2024-04-25 18:13:42,161 Epoch number 27, batch number 2/4:       batch loss 0.0034389488864690065
2024-04-25 18:13:44,101 Epoch number 27, batch number 3/4:       batch loss 0.00320769427344203
2024-04-25 18:13:46,791 Epoch number 27, batch number 0/1:       batch loss 0.003044992918148637
2024-04-25 18:13:47,034 Epoch: 28 	Training Loss: 0.000162
2024-04-25 18:13:47,034 Time for epoch 28 : 13 sec
2024-04-25 18:13:47,034 lr for epoch 28 is 0.01000
2024-04-25 18:13:51,036 Epoch number 28, batch number 0/4:       batch loss 0.002997265662997961
2024-04-25 18:13:53,426 Epoch number 28, batch number 1/4:       batch loss 0.0032157383393496275
2024-04-25 18:13:55,417 Epoch number 28, batch number 2/4:       batch loss 0.003832054790109396
2024-04-25 18:13:57,332 Epoch number 28, batch number 3/4:       batch loss 0.0036673799622803926
2024-04-25 18:14:00,058 Epoch number 28, batch number 0/1:       batch loss 0.003592564258724451
2024-04-25 18:14:00,266 Epoch: 29 	Training Loss: 0.000171
2024-04-25 18:14:00,266 Time for epoch 29 : 13 sec
2024-04-25 18:14:00,266 lr for epoch 29 is 0.01000
2024-04-25 18:14:04,233 Epoch number 29, batch number 0/4:       batch loss 0.004113489296287298
2024-04-25 18:14:06,565 Epoch number 29, batch number 1/4:       batch loss 0.002985166385769844
2024-04-25 18:14:08,542 Epoch number 29, batch number 2/4:       batch loss 0.00405925465747714
2024-04-25 18:14:10,458 Epoch number 29, batch number 3/4:       batch loss 0.002527030184864998
2024-04-25 18:14:13,218 Epoch number 29, batch number 0/1:       batch loss 0.0031272266060113907
2024-04-25 18:14:13,436 Epoch: 30 	Training Loss: 0.000171
2024-04-25 18:14:13,436 Time for epoch 30 : 13 sec
2024-04-25 18:14:13,436 lr for epoch 30 is 0.01000
2024-04-25 18:14:17,364 Epoch number 30, batch number 0/4:       batch loss 0.003006641287356615
2024-04-25 18:14:19,723 Epoch number 30, batch number 1/4:       batch loss 0.0031359053682535887
2024-04-25 18:14:21,693 Epoch number 30, batch number 2/4:       batch loss 0.003931726329028606
2024-04-25 18:14:23,717 Epoch number 30, batch number 3/4:       batch loss 0.002920320723205805
2024-04-25 18:14:26,370 Epoch number 30, batch number 0/1:       batch loss 0.0035323314368724823
2024-04-25 18:14:26,582 Epoch: 31 	Training Loss: 0.000162
2024-04-25 18:14:26,583 Time for epoch 31 : 13 sec
2024-04-25 18:14:26,583 lr for epoch 31 is 0.01000
2024-04-25 18:14:30,555 Epoch number 31, batch number 0/4:       batch loss 0.0038463310338556767
2024-04-25 18:14:32,918 Epoch number 31, batch number 1/4:       batch loss 0.0037702240515500307
2024-04-25 18:14:34,976 Epoch number 31, batch number 2/4:       batch loss 0.003032730193808675
2024-04-25 18:14:36,928 Epoch number 31, batch number 3/4:       batch loss 0.003503721207380295
2024-04-25 18:14:39,709 Epoch number 31, batch number 0/1:       batch loss 0.0035263511817902327
2024-04-25 18:14:39,919 Epoch: 32 	Training Loss: 0.000177
2024-04-25 18:14:39,919 Time for epoch 32 : 13 sec
2024-04-25 18:14:39,919 lr for epoch 32 is 0.01000
2024-04-25 18:14:43,941 Epoch number 32, batch number 0/4:       batch loss 0.00256354920566082
2024-04-25 18:14:46,390 Epoch number 32, batch number 1/4:       batch loss 0.002873226534575224
2024-04-25 18:14:48,372 Epoch number 32, batch number 2/4:       batch loss 0.002892755437642336
2024-04-25 18:14:50,331 Epoch number 32, batch number 3/4:       batch loss 0.0025273910723626614
2024-04-25 18:14:53,049 Epoch number 32, batch number 0/1:       batch loss 0.0030680042691528797
2024-04-25 18:14:53,260 Epoch: 33 	Training Loss: 0.000136
2024-04-25 18:14:53,260 Time for epoch 33 : 13 sec
2024-04-25 18:14:53,260 lr for epoch 33 is 0.01000
2024-04-25 18:14:57,404 Epoch number 33, batch number 0/4:       batch loss 0.0023599329870194197
2024-04-25 18:14:59,789 Epoch number 33, batch number 1/4:       batch loss 0.003475004807114601
2024-04-25 18:15:01,794 Epoch number 33, batch number 2/4:       batch loss 0.002483271760866046
2024-04-25 18:15:03,827 Epoch number 33, batch number 3/4:       batch loss 0.0021178200840950012
2024-04-25 18:15:06,561 Epoch number 33, batch number 0/1:       batch loss 0.003101247362792492
2024-04-25 18:15:06,798 Epoch: 34 	Training Loss: 0.000130
2024-04-25 18:15:06,798 Time for epoch 34 : 14 sec
2024-04-25 18:15:06,798 lr for epoch 34 is 0.01000
2024-04-25 18:15:10,698 Epoch number 34, batch number 0/4:       batch loss 0.0028880764730274677
2024-04-25 18:15:13,075 Epoch number 34, batch number 1/4:       batch loss 0.0023793175350874662
2024-04-25 18:15:15,065 Epoch number 34, batch number 2/4:       batch loss 0.0032887677662074566
2024-04-25 18:15:17,034 Epoch number 34, batch number 3/4:       batch loss 0.0027182139456272125
2024-04-25 18:15:19,784 Epoch number 34, batch number 0/1:       batch loss 0.0027367710135877132
2024-04-25 18:15:20,020 Epoch: 35 	Training Loss: 0.000141
2024-04-25 18:15:20,020 Time for epoch 35 : 13 sec
2024-04-25 18:15:20,020 lr for epoch 35 is 0.01000
2024-04-25 18:15:23,974 Epoch number 35, batch number 0/4:       batch loss 0.002266803290694952
2024-04-25 18:15:26,406 Epoch number 35, batch number 1/4:       batch loss 0.0029405024833977222
2024-04-25 18:15:28,419 Epoch number 35, batch number 2/4:       batch loss 0.003176309634000063
2024-04-25 18:15:30,357 Epoch number 35, batch number 3/4:       batch loss 0.0026041611563414335
2024-04-25 18:15:33,082 Epoch number 35, batch number 0/1:       batch loss 0.002453629160299897
2024-04-25 18:15:33,295 Epoch: 36 	Training Loss: 0.000137
2024-04-25 18:15:33,295 Time for epoch 36 : 13 sec
2024-04-25 18:15:33,295 lr for epoch 36 is 0.01000
2024-04-25 18:15:37,235 Epoch number 36, batch number 0/4:       batch loss 0.0023333921562880278
2024-04-25 18:15:39,664 Epoch number 36, batch number 1/4:       batch loss 0.0024566538631916046
2024-04-25 18:15:41,661 Epoch number 36, batch number 2/4:       batch loss 0.00235571782104671
2024-04-25 18:15:43,604 Epoch number 36, batch number 3/4:       batch loss 0.002654372714459896
2024-04-25 18:15:46,242 Epoch number 36, batch number 0/1:       batch loss 0.002480464754626155
2024-04-25 18:15:46,456 Epoch: 37 	Training Loss: 0.000123
2024-04-25 18:15:46,456 Time for epoch 37 : 13 sec
2024-04-25 18:15:46,456 lr for epoch 37 is 0.01000
2024-04-25 18:15:50,379 Epoch number 37, batch number 0/4:       batch loss 0.0020201948937028646
2024-04-25 18:15:54,366 Epoch number 37, batch number 1/4:       batch loss 0.005866463761776686
2024-04-25 18:15:57,865 Epoch number 37, batch number 2/4:       batch loss 0.02058018371462822
2024-04-25 18:16:01,275 Epoch number 37, batch number 3/4:       batch loss 0.02687993086874485
2024-04-25 18:16:04,327 Epoch number 37, batch number 0/1:       batch loss 0.02007807232439518
2024-04-25 18:16:04,546 Epoch: 38 	Training Loss: 0.000692
2024-04-25 18:16:04,546 Time for epoch 38 : 18 sec
2024-04-25 18:16:04,546 lr for epoch 38 is 0.01000
2024-04-25 18:16:10,079 Epoch number 38, batch number 0/4:       batch loss 0.01479257456958294
2024-04-25 18:16:14,037 Epoch number 38, batch number 1/4:       batch loss 0.015388885512948036
2024-04-25 18:16:17,455 Epoch number 38, batch number 2/4:       batch loss 0.014576760120689869
2024-04-25 18:16:20,819 Epoch number 38, batch number 3/4:       batch loss 0.019396023824810982
2024-04-25 18:16:23,897 Epoch number 38, batch number 0/1:       batch loss 0.024709081277251244
2024-04-25 18:16:24,088 Epoch: 39 	Training Loss: 0.000802
2024-04-25 18:16:24,088 Time for epoch 39 : 20 sec
2024-04-25 18:16:24,088 lr for epoch 39 is 0.01000
2024-04-25 18:16:29,907 Epoch number 39, batch number 0/4:       batch loss 0.022115394473075867
2024-04-25 18:16:33,924 Epoch number 39, batch number 1/4:       batch loss 0.02317493036389351
2024-04-25 18:16:37,388 Epoch number 39, batch number 2/4:       batch loss 0.007368137128651142
2024-04-25 18:16:40,827 Epoch number 39, batch number 3/4:       batch loss 0.01812100224196911
2024-04-25 18:16:43,949 Epoch number 39, batch number 0/1:       batch loss 0.01946900598704815
2024-04-25 18:16:44,165 Epoch: 40 	Training Loss: 0.000885
2024-04-25 18:16:44,165 Time for epoch 40 : 20 sec
2024-04-25 18:16:44,165 lr for epoch 40 is 0.01000
2024-04-25 18:17:00,390 Epoch number 0, batch number 0/1:       batch loss 0.012697054073214531
2024-04-25 18:17:00,493 Epoch: 1 	Training Loss: 0.000635
2024-04-25 18:17:00,493 Time for epoch 1 : 13 sec
2024-04-25 18:17:00,493 lr for epoch 1 is 0.01000
2024-04-25 18:17:02,901 Epoch number 0, batch number 0/1:       batch loss 0.012560655362904072
2024-04-25 18:17:15,913 Epoch number 1, batch number 0/1:       batch loss 0.010961594991385937
2024-04-25 18:17:16,003 Epoch: 2 	Training Loss: 0.000548
2024-04-25 18:17:16,003 Time for epoch 2 : 13 sec
2024-04-25 18:17:16,004 lr for epoch 2 is 0.01000
2024-04-25 18:17:18,425 Epoch number 1, batch number 0/1:       batch loss 0.033861301839351654
2024-04-25 18:17:31,704 Epoch number 2, batch number 0/1:       batch loss 0.026202499866485596
2024-04-25 18:17:31,795 Epoch: 3 	Training Loss: 0.001310
2024-04-25 18:17:31,796 Time for epoch 3 : 13 sec
2024-04-25 18:17:31,796 lr for epoch 3 is 0.01000
2024-04-25 18:17:34,234 Epoch number 2, batch number 0/1:       batch loss 0.04208577051758766
2024-04-25 18:17:47,155 Epoch number 3, batch number 0/1:       batch loss 0.026415809988975525
2024-04-25 18:17:47,247 Epoch: 4 	Training Loss: 0.001321
2024-04-25 18:17:47,247 Time for epoch 4 : 13 sec
2024-04-25 18:17:47,247 lr for epoch 4 is 0.01000
2024-04-25 18:17:49,778 Epoch number 3, batch number 0/1:       batch loss 0.023075677454471588
2024-04-25 18:18:02,719 Epoch number 4, batch number 0/1:       batch loss 0.024070490151643753
2024-04-25 18:18:02,808 Epoch: 5 	Training Loss: 0.001204
2024-04-25 18:18:02,809 Time for epoch 5 : 13 sec
2024-04-25 18:18:02,809 lr for epoch 5 is 0.01000
2024-04-25 18:18:05,259 Epoch number 4, batch number 0/1:       batch loss 0.011143559589982033
2024-04-25 18:18:18,326 Epoch number 5, batch number 0/1:       batch loss 0.011562839150428772
2024-04-25 18:18:18,418 Epoch: 6 	Training Loss: 0.000578
2024-04-25 18:18:18,418 Time for epoch 6 : 13 sec
2024-04-25 18:18:18,418 lr for epoch 6 is 0.01000
2024-04-25 18:18:21,150 Epoch number 5, batch number 0/1:       batch loss 0.00648686895146966
2024-04-25 18:18:34,073 Epoch number 6, batch number 0/1:       batch loss 0.00547016179189086
2024-04-25 18:18:34,165 Epoch: 7 	Training Loss: 0.000274
2024-04-25 18:18:34,165 Time for epoch 7 : 13 sec
2024-04-25 18:18:34,165 lr for epoch 7 is 0.01000
2024-04-25 18:18:36,673 Epoch number 6, batch number 0/1:       batch loss 0.03559650108218193
2024-04-25 18:18:49,620 Epoch number 7, batch number 0/1:       batch loss 0.025449207052588463
2024-04-25 18:18:49,711 Epoch: 8 	Training Loss: 0.001272
2024-04-25 18:18:49,711 Time for epoch 8 : 13 sec
2024-04-25 18:18:49,711 lr for epoch 8 is 0.01000
2024-04-25 18:18:52,154 Epoch number 7, batch number 0/1:       batch loss 0.018053513020277023
2024-04-25 18:19:05,101 Epoch number 8, batch number 0/1:       batch loss 0.018090078607201576
2024-04-25 18:19:05,191 Epoch: 9 	Training Loss: 0.000905
2024-04-25 18:19:05,191 Time for epoch 9 : 13 sec
2024-04-25 18:19:05,191 lr for epoch 9 is 0.01000
2024-04-25 18:19:07,670 Epoch number 8, batch number 0/1:       batch loss 0.009727082215249538
2024-04-25 18:19:20,668 Epoch number 9, batch number 0/1:       batch loss 0.0066199772991240025
2024-04-25 18:19:20,775 Epoch: 10 	Training Loss: 0.000331
2024-04-25 18:19:20,775 Time for epoch 10 : 13 sec
2024-04-25 18:19:20,775 lr for epoch 10 is 0.01000
2024-04-25 18:19:23,208 Epoch number 9, batch number 0/1:       batch loss 0.006049523130059242
2024-04-25 18:19:51,696 findfont: Font family 'Arial' not found.
2024-04-25 18:19:51,696 findfont: Font family 'Arial' not found.
2024-04-25 18:19:51,696 findfont: Font family 'Times New Roman' not found.
2024-04-25 18:19:51,696 findfont: Font family 'Times New Roman' not found.
2024-04-25 18:19:51,703 findfont: Font family 'Arial' not found.
2024-04-25 18:19:51,703 findfont: Font family 'Arial' not found.
2024-04-25 18:19:51,708 findfont: Font family 'Arial' not found.
2024-04-25 18:19:51,709 findfont: Font family 'Times New Roman' not found.
2024-04-25 18:20:19,970 findfont: Font family 'Arial' not found.
2024-04-25 18:20:19,970 findfont: Font family 'Arial' not found.
2024-04-25 18:20:19,970 findfont: Font family 'Times New Roman' not found.
2024-04-25 18:20:19,970 findfont: Font family 'Times New Roman' not found.
2024-04-25 18:20:19,977 findfont: Font family 'Arial' not found.
2024-04-25 18:20:19,977 findfont: Font family 'Arial' not found.
2024-04-25 18:20:19,980 findfont: Font family 'Arial' not found.
2024-04-25 18:20:19,982 findfont: Font family 'Times New Roman' not found.
2024-04-25 18:20:48,285 findfont: Font family 'Arial' not found.
2024-04-25 18:20:48,285 findfont: Font family 'Arial' not found.
2024-04-25 18:20:48,285 findfont: Font family 'Times New Roman' not found.
2024-04-25 18:20:48,286 findfont: Font family 'Times New Roman' not found.
2024-04-25 18:20:48,292 findfont: Font family 'Arial' not found.
2024-04-25 18:20:48,292 findfont: Font family 'Arial' not found.
2024-04-25 18:20:48,297 findfont: Font family 'Arial' not found.
2024-04-25 18:20:48,298 findfont: Font family 'Times New Roman' not found.
2024-04-25 18:20:56,067 Run Finished Successfully
